{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_info: \n",
      " tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_path='C:\\\\Users\\\\prizl\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=11.06 MiB,\n",
      "    dataset_size=21.00 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# 2.1 Load Dataset\n",
    "(train_ds, test_ds), ds_info = tfds.load ('mnist', split =['train', 'test'], as_supervised = True, with_info = True)\n",
    "\n",
    "print(\"ds_info: \\n\", ds_info)\n",
    "# tfds.show_examples(train_ds, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_target_fnc(ds, sequence_len):\n",
    "        \"\"\"\n",
    "        Creates list of new targets by alternately adding and subtracting\n",
    "        The first digit is added, the second subtracted, the third added, etc\n",
    "        Parameters\n",
    "        ----------\n",
    "        ds : TensorFlowDataset\n",
    "        original mnist dataset containg images and targets as a tuple.\n",
    "        sequence_len : int\n",
    "        indicates at which point the sum has to reset for the new sequence\n",
    "        Returns\n",
    "        -------\n",
    "        l : list\n",
    "        list containing the new targets\n",
    "        \"\"\"\n",
    "        \n",
    "        t = list()\n",
    "        for i, v in enumerate(ds):\n",
    "            if i % sequence_len == 0:\n",
    "                t.append(v)\n",
    "                \n",
    "            elif i % 2 != 0:\n",
    "                a = t[i-1] - v  \n",
    "                t.append(a)\n",
    "\n",
    "            elif i % 2 == 0:\n",
    "                a = t[i-1] + v \n",
    "                t.append(a)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, -1, 2, 4]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_target_fnc([1,2,3,4], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Data Pipeline\n",
    "def preprocess(dataset, batchsize, sequence_len):\n",
    "\n",
    "    '''\n",
    "    :param dataset: the dataset to be prepared for input into the network\n",
    "    :param batchsize: the desired batchsize\n",
    "    :return: 2 datasets, one each for each of the math problems defined (see below), created after the original database was preprocessed with the\n",
    "    steps below\n",
    "    '''\n",
    "\n",
    "    # Step 1 - General Preprocessing\n",
    "\n",
    "    # convert data from uint8 to float32\n",
    "    dataset = dataset.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "\n",
    "    # flatten the images into vectors\n",
    "    # dataset = dataset.map(lambda img, target: (tf.reshape(img, (-1,)), target))\n",
    "\n",
    "    # input normalization, just bringing image values from range [0, 255] to [-1, 1]\n",
    "    dataset = dataset.map(lambda img, target: ((img / 128.) - 1., target))\n",
    "\n",
    "    # data = tf.data.Dataset.zip((dataset.shuffle(2000), dataset.shuffle(2000)))\n",
    "\n",
    "    # print(dataset.shape)\n",
    "    # The output of that lambda function should be a tuple of two tensors of shapes (num_images, height, width, 1) and (num_images, 1) or (num_images,)\n",
    "    \n",
    "    # Step 2 - Pairing Data Tuples & Respective Parameterized Targets\n",
    "\n",
    "    # create a dataset that contains 2000 samples from the overall dataset paired with 2000 other samples\n",
    "    # data = tf.data.Dataset.zip((dataset.shuffle(2000), dataset.shuffle(2000), dataset.shuffle(2000), dataset.shuffle(2000)))\n",
    "    \n",
    "    # create the dataset for the first math problem (a + b >= 5) - remembering to cast to int versus boolean!\n",
    "    # first = data.map(lambda x1, x2, x3, x4: (x1[0], x2[0], x3[0], x4[0], x1[1]))\n",
    "    # second = data.map(lambda x1, x2, x3, x4: (x1[0], x2[0], x3[0], x4[0], x1[1] - x2[1]))\n",
    "    # third = data.map(lambda x1, x2, x3, x4: (x1[0], x2[0], x3[0], x4[0], x1[1] - x2[1] + x3[1]))\n",
    "    # fourth = data.map(lambda x1, x2, x3, x4: (x1[0], x2[0], x3[0], x4[0], x1[1] - x2[1] + x3[1] - x4[1]))\n",
    "    \n",
    "    # list = [first, second, third, fourth]\n",
    "\n",
    "    sequenc_len = 4\n",
    "    \n",
    "    dataset = dataset.map(lambda img, target: img, new_target_fnc(target, sequenc_len))\n",
    "\n",
    "    # Step 3 - Batching & Prefetching\n",
    "    # new = new_target_fnc(data, sequence_len)\n",
    "    new = dataset.batch(batchsize)\n",
    "    new = new.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # The shape of your tensors should be (batch, sequence-length, features). \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1) (32,)\n",
      "(32, 28, 28, 1) (32,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ds = preprocess(train_ds, 32, 4)\n",
    "test_ds = preprocess(test_ds, 32, 4)\n",
    "\n",
    "for img1, label in train_ds.take(1):\n",
    "    print(img1.shape, label.shape)\n",
    "\n",
    "# (bs, num_images, height, width, 1)\n",
    "\n",
    "for img1, label in test_ds.take(1):\n",
    "    print(img1.shape, label.shape)\n",
    "    \n",
    "# (bs, num_images, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 Finding the targets (instruction still in revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 The CNN & LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(tf.keras.Model):\n",
    "    def __init__(self, batch, sequence_length, image):\n",
    "        super(BasicConv, self).__init__()\n",
    "\n",
    "        # input 32x32x3 with 3 as the color channels\n",
    "        self.convlayer1 = tf.keras.layers.Conv2D(filters=48, kernel_size=3, padding='same', activation='relu') # after this: 32x32x24\n",
    "        # self.convlayer2 = tf.keras.layers.Conv2D(filters=48, kernel_size=3, padding='same', activation='relu') # 32x32x24\n",
    "        # self.convlayer3 = tf.keras.layers.Conv2D(filters=48, kernel_size=3, padding='same', activation='relu') # 32x32x24\n",
    "\n",
    "        # self.pooling = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2) # 16x16x24\n",
    "\n",
    "        # self.normlayer = tf.keras.layers.Normalization(axis=-1,mean=None,invert=False)\n",
    "\n",
    "        # self.convlayer4 = tf.keras.layers.Conv2D(filters=72, kernel_size=3, padding='same', activation='relu') # 16x16x72\n",
    "        # self.convlayer5 = tf.keras.layers.Conv2D(filters=72, kernel_size=3, padding='same', activation='relu') # 16x16x72\n",
    "        # self.convlayer6 = tf.keras.layers.Conv2D(filters=72, kernel_size=3, padding='same', activation='relu') # 16x16x72\n",
    "\n",
    "        self.global_pool = tf.keras.layers.GlobalAvgPool2D() # 1x1x72\n",
    "\n",
    "        # self.out = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "        self.loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        self.metrics_list = [\n",
    "                    tf.keras.metrics.Mean(name=\"loss\"),\n",
    "                    tf.keras.metrics.BinaryAccuracy(name=\"acc\"), # only for subtask 0, not for subtask 1\n",
    "                    ]\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        x = self.convlayer1(x) ## trying it out as simple as possible\n",
    "        # x = self.convlayer2(x)\n",
    "        # x = self.convlayer3(x)\n",
    "        # x = self.pooling(x)\n",
    "        # x = self.convlayer4(x)\n",
    "        # x = self.convlayer5(x)\n",
    "        # x = self.convlayer6(x)\n",
    "        # x = self.global_pool(x)\n",
    "        x = tf.keras.layers.TimeDistributed(self.global_pool())(x)\n",
    "\n",
    "        # Once you have encoded all images as vectors, the shape of the tensor should be (batch, sequence-length, features), \n",
    "        # which can be fed to a non-convolutional standard LSTM.\n",
    "        return x\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, input):\n",
    "        img, label = input\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = self(img, training=True)\n",
    "            loss = self.loss_function(label, prediction)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        # update loss metric\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        # for all metrics except loss, update states (accuracy etc.)\n",
    "        for metric in self.metrics[1:]:\n",
    "            metric.update_state(label, prediction) # + tf.reduce_sum(self.losses)\n",
    "\n",
    "        # return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, input):\n",
    "\n",
    "        img, label = input\n",
    "\n",
    "        prediction = self(img, training=False)\n",
    "        loss = self.loss_function(label, prediction) # + tf.reduce_sum(self.losses)\n",
    "\n",
    "        # update loss metric\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        # for accuracy metrics:\n",
    "        for metric in self.metrics[1:]:\n",
    "            metric.update_state(label, prediction)\n",
    "\n",
    "        # return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 LSTM AbstractRNNCell layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9045caf6303e7720903cf179822b02fa228c285a06d63d48b635a33538dcbdb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
