{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_info: \n",
      " tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_path='C:\\\\Users\\\\prizl\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=11.06 MiB,\n",
      "    dataset_size=21.00 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 2.1 Load Dataset\n",
    "(train_ds, test_ds), ds_info = tfds.load ('mnist', split =['train', 'test'], as_supervised = True, with_info = True)\n",
    "\n",
    "print(\"ds_info: \\n\", ds_info)\n",
    "# tfds.show_examples(train_ds, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_target_fnc(ds, sequence_len):\n",
    "        \"\"\"\n",
    "        Creates list of new targets by alternately adding and subtracting\n",
    "        The first digit is added, the second subtracted, the third added, etc\n",
    "        Parameters\n",
    "        ----------\n",
    "        ds : TensorFlowDataset\n",
    "        original mnist dataset containg images and targets as a tuple.\n",
    "        sequence_len : int\n",
    "        indicates at which point the sum has to reset for the new sequence\n",
    "        Returns\n",
    "        -------\n",
    "        l : list\n",
    "        list containing the new targets\n",
    "        \"\"\"\n",
    "        \n",
    "        t = list()\n",
    "        for i, v in enumerate(ds):\n",
    "            if i % sequence_len == 0:\n",
    "                t.append(v)\n",
    "                \n",
    "            elif i % 2 != 0:\n",
    "                a = t[i-1] - v  \n",
    "                t.append(a)\n",
    "\n",
    "            elif i % 2 == 0:\n",
    "                a = t[i-1] + v \n",
    "                t.append(a)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, -1, 2, 4]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_target_fnc([1,2,3,4], 3)\n",
    "\n",
    "t.append(v) for i, v in enumerate(ds) if i % sequence_len ==0 elif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Data Pipeline\n",
    "def preprocess(dataset, batchsize, sequence_len):\n",
    "\n",
    "    '''\n",
    "    :param dataset: the dataset to be prepared for input into the network\n",
    "    :param batchsize: the desired batchsize\n",
    "    :return: 2 datasets, one each for each of the math problems defined (see below), created after the original database was preprocessed with the\n",
    "    steps below\n",
    "    '''\n",
    "\n",
    "    # Step 1 - General Preprocessing\n",
    "\n",
    "    # convert data from uint8 to float32\n",
    "    dataset = dataset.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "\n",
    "    # flatten the images into vectors\n",
    "    # dataset = dataset.map(lambda img, target: (tf.reshape(img, (-1,)), target))\n",
    "\n",
    "    # input normalization, just bringing image values from range [0, 255] to [-1, 1]\n",
    "    dataset = dataset.map(lambda img, target: ((img / 128.) - 1., target))\n",
    "\n",
    "    # data = tf.data.Dataset.zip((dataset.shuffle(2000), dataset.shuffle(2000)))\n",
    "\n",
    "    # print(dataset.shape)\n",
    "    # The output of that lambda function should be a tuple of two tensors of shapes (num_images, height, width, 1) and (num_images, 1) or (num_images,)\n",
    "    \n",
    "    # Step 2 - Pairing Data Tuples & Respective Parameterized Targets\n",
    "\n",
    "    # create a dataset that contains 2000 samples from the overall dataset paired with 2000 other samples\n",
    "    # data = tf.data.Dataset.zip((dataset.shuffle(2000), dataset.shuffle(2000), dataset.shuffle(2000), dataset.shuffle(2000)))\n",
    "    \n",
    "    # create the dataset for the first math problem (a + b >= 5) - remembering to cast to int versus boolean!\n",
    "    # first = data.map(lambda x1, x2, x3, x4: (x1[0], x2[0], x3[0], x4[0], x1[1]))\n",
    "    # second = data.map(lambda x1, x2, x3, x4: (x1[0], x2[0], x3[0], x4[0], x1[1] - x2[1]))\n",
    "    # third = data.map(lambda x1, x2, x3, x4: (x1[0], x2[0], x3[0], x4[0], x1[1] - x2[1] + x3[1]))\n",
    "    # fourth = data.map(lambda x1, x2, x3, x4: (x1[0], x2[0], x3[0], x4[0], x1[1] - x2[1] + x3[1] - x4[1]))\n",
    "    \n",
    "    # list = [first, second, third, fourth]\n",
    "    \n",
    "    # dataset = dataset.map(lambda img, target: img, new_target_fnc(target, sequence_len))\n",
    "\n",
    "    # Step 3 - Batching & Prefetching\n",
    "    # new = new_target_fnc(data, sequence_len)\n",
    "    dataset = dataset.batch(sequence_len)\n",
    "\n",
    "    # labels = np.concatenate([label for img, label in dataset], axis=0)\n",
    "    labels = [labels for _, labels in dataset.unbatch()]\n",
    "    new_labels = new_target_fnc(labels, sequence_len)\n",
    "    \n",
    "    # dataset = dataset.map(lambda img, target: img, new_labels)\n",
    "    dataset = tf.data.Dataset.zip(dataset, new_labels)\n",
    "    # dataset = dataset.map(lambda img, target1, target2: img, target1))\n",
    "    # dataset = dataset.map(lambda img, target: img, tf.data.Dataset.from_tensor_slices(target))\n",
    "    \n",
    "    # create a dataset that contains 2000 samples from the overall dataset paired with 2000 other samples\n",
    "    # dataset = tf.data.Dataset.zip((dataset.shuffle(2000), dataset.shuffle(2000)))\n",
    "    \n",
    "    dataset = dataset.batch(batchsize)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # The shape of your tensors should be (batch, sequence-length, features). \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'isidentifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\prizl\\Documents\\GitHub\\IANNwTFGr10\\Homework\\07\\Gr10HW07.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_ds \u001b[39m=\u001b[39m preprocess(train_ds, \u001b[39m32\u001b[39;49m, \u001b[39m4\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_ds \u001b[39m=\u001b[39m preprocess(test_ds, \u001b[39m32\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m img, label \u001b[39m=\u001b[39m train_ds\n",
      "\u001b[1;32mc:\\Users\\prizl\\Documents\\GitHub\\IANNwTFGr10\\Homework\\07\\Gr10HW07.ipynb Cell 7\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(dataset, batchsize, sequence_len)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m new_labels \u001b[39m=\u001b[39m new_target_fnc(labels, sequence_len)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# dataset = dataset.map(lambda img, target: img, new_labels)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mzip(dataset, new_labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# dataset = dataset.map(lambda img, target1, target2: img, target1))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# dataset = dataset.map(lambda img, target: img, tf.data.Dataset.from_tensor_slices(target))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# create a dataset that contains 2000 samples from the overall dataset paired with 2000 other samples\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# dataset = tf.data.Dataset.zip((dataset.shuffle(2000), dataset.shuffle(2000)))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/07/Gr10HW07.ipynb#X15sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mbatch(batchsize)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1259\u001b[0m, in \u001b[0;36mDatasetV2.zip\u001b[1;34m(datasets, name)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mzip\u001b[39m(datasets, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1215\u001b[0m   \u001b[39m\"\"\"Creates a `Dataset` by zipping together the given datasets.\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \n\u001b[0;32m   1217\u001b[0m \u001b[39m  This method has similar semantics to the built-in `zip()` function\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   1258\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1259\u001b[0m   \u001b[39mreturn\u001b[39;00m ZipDataset(datasets, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4699\u001b[0m, in \u001b[0;36mZipDataset.__init__\u001b[1;34m(self, datasets, name)\u001b[0m\n\u001b[0;32m   4693\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4694\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datasets,\n\u001b[0;32m   4695\u001b[0m     [ds\u001b[39m.\u001b[39melement_spec \u001b[39mfor\u001b[39;00m ds \u001b[39min\u001b[39;00m nest\u001b[39m.\u001b[39mflatten(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datasets)])\n\u001b[0;32m   4696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m   4697\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mzip_dataset(\n\u001b[0;32m   4698\u001b[0m     [ds\u001b[39m.\u001b[39m_variant_tensor \u001b[39mfor\u001b[39;00m ds \u001b[39min\u001b[39;00m nest\u001b[39m.\u001b[39mflatten(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_datasets)],\n\u001b[1;32m-> 4699\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_common_args)\n\u001b[0;32m   4700\u001b[0m \u001b[39msuper\u001b[39m(ZipDataset, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(variant_tensor)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:683\u001b[0m, in \u001b[0;36mDatasetV2._common_args\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    668\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_common_args\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    669\u001b[0m   \u001b[39m\"\"\"Helper for generating arguments that are common across most dataset ops.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \n\u001b[0;32m    671\u001b[0m \u001b[39m  Most dataset op constructors expect `output_shapes` and `output_types`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[39m    constructor.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m    682\u001b[0m   \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m--> 683\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metadata\u001b[39m.\u001b[39mSerializeToString(),\n\u001b[0;32m    684\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39moutput_shapes\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_shapes,\n\u001b[0;32m    685\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39moutput_types\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_types,\n\u001b[0;32m    686\u001b[0m   }\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:664\u001b[0m, in \u001b[0;36mDatasetV2._metadata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    662\u001b[0m metadata \u001b[39m=\u001b[39m dataset_metadata_pb2\u001b[39m.\u001b[39mMetadata()\n\u001b[0;32m    663\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name:\n\u001b[1;32m--> 664\u001b[0m   metadata\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m _validate_and_encode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name)\n\u001b[0;32m    665\u001b[0m \u001b[39mreturn\u001b[39;00m metadata\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:114\u001b[0m, in \u001b[0;36m_validate_and_encode\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_and_encode\u001b[39m(name):\n\u001b[1;32m--> 114\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m name\u001b[39m.\u001b[39;49misidentifier():\n\u001b[0;32m    115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid `name`. The argument `name` needs to be a valid \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39midentifier. Value is considered a valid identifier if it \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39monly contains alphanumeric characters (a-z), (A-Z), and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m(0-9), or underscores (_). A valid identifier cannot \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mstart with a number, or contain any spaces.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    120\u001b[0m   \u001b[39mreturn\u001b[39;00m name\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'isidentifier'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ds = preprocess(train_ds, 32, 4)\n",
    "test_ds = preprocess(test_ds, 32, 4)\n",
    "\n",
    "img, label = train_ds\n",
    "\n",
    "# print(label.shape)\n",
    "for img1, label0, label in train_ds.take(1):\n",
    "    print(img1.shape, label.shape)\n",
    "\n",
    "# (bs, num_images, height, width, 1)\n",
    "\n",
    "for img1, label0, label in test_ds.take(1):\n",
    "    print(img1.shape, label.shape)\n",
    "    \n",
    "# (bs, num_images, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 Finding the targets (instruction still in revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 The CNN & LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(tf.keras.Model):\n",
    "    def __init__(self, batch, sequence_length, image):\n",
    "        super(BasicConv, self).__init__()\n",
    "\n",
    "        # input 32x32x3 with 3 as the color channels\n",
    "        self.convlayer1 = tf.keras.layers.Conv2D(filters=48, kernel_size=3, padding='same', activation='relu') # after this: 32x32x24\n",
    "        # self.convlayer2 = tf.keras.layers.Conv2D(filters=48, kernel_size=3, padding='same', activation='relu') # 32x32x24\n",
    "        # self.convlayer3 = tf.keras.layers.Conv2D(filters=48, kernel_size=3, padding='same', activation='relu') # 32x32x24\n",
    "\n",
    "        # self.pooling = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2) # 16x16x24\n",
    "\n",
    "        # self.normlayer = tf.keras.layers.Normalization(axis=-1,mean=None,invert=False)\n",
    "\n",
    "        # self.convlayer4 = tf.keras.layers.Conv2D(filters=72, kernel_size=3, padding='same', activation='relu') # 16x16x72\n",
    "        # self.convlayer5 = tf.keras.layers.Conv2D(filters=72, kernel_size=3, padding='same', activation='relu') # 16x16x72\n",
    "        # self.convlayer6 = tf.keras.layers.Conv2D(filters=72, kernel_size=3, padding='same', activation='relu') # 16x16x72\n",
    "\n",
    "        self.global_pool = tf.keras.layers.GlobalAvgPool2D() # 1x1x72\n",
    "\n",
    "        # self.out = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "        self.loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        self.metrics_list = [\n",
    "                    tf.keras.metrics.Mean(name=\"loss\"),\n",
    "                    tf.keras.metrics.BinaryAccuracy(name=\"acc\"), # only for subtask 0, not for subtask 1\n",
    "                    ]\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        x = self.convlayer1(x) ## trying it out as simple as possible\n",
    "        # x = self.convlayer2(x)\n",
    "        # x = self.convlayer3(x)\n",
    "        # x = self.pooling(x)\n",
    "        # x = self.convlayer4(x)\n",
    "        # x = self.convlayer5(x)\n",
    "        # x = self.convlayer6(x)\n",
    "        # x = self.global_pool(x)\n",
    "        x = tf.keras.layers.TimeDistributed(self.global_pool())(x)\n",
    "\n",
    "        # Once you have encoded all images as vectors, the shape of the tensor should be (batch, sequence-length, features), \n",
    "        # which can be fed to a non-convolutional standard LSTM.\n",
    "        return x\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, input):\n",
    "        img, label = input\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = self(img, training=True)\n",
    "            loss = self.loss_function(label, prediction)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        # update loss metric\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        # for all metrics except loss, update states (accuracy etc.)\n",
    "        for metric in self.metrics[1:]:\n",
    "            metric.update_state(label, prediction) # + tf.reduce_sum(self.losses)\n",
    "\n",
    "        # return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, input):\n",
    "\n",
    "        img, label = input\n",
    "\n",
    "        prediction = self(img, training=False)\n",
    "        loss = self.loss_function(label, prediction) # + tf.reduce_sum(self.losses)\n",
    "\n",
    "        # update loss metric\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        # for accuracy metrics:\n",
    "        for metric in self.metrics[1:]:\n",
    "            metric.update_state(label, prediction)\n",
    "\n",
    "        # return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 LSTM AbstractRNNCell layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9045caf6303e7720903cf179822b02fa228c285a06d63d48b635a33538dcbdb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
