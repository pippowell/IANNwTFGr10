{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IANNwTF HW 4\n",
    "## Group 10\n",
    "\n",
    "The following contains our solution to the exercises in IANNwTF HW 04. A Jupyter notebook versus a module format was chosen this time for purposes of organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assigment 1: Reviews\n",
    "We review the homeworks for Groups 15 and 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 2: MNIST Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 Preparing the MNIST Math Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Needed Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\prizl\\Documents\\GitHub\\IANNwTFGr10\\Homework\\04\\Gr10HW04.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a, b \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m a\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "a, b = [1,2,3,4]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\prizl\\Documents\\GitHub\\IANNwTFGr10\\Homework\\04\\Gr10HW04.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m (train_ds, test_ds), ds_info \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39mload (\u001b[39m'\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m'\u001b[39m, split \u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m], as_supervised \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, with_info \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Info on the dataset (refresher)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# print(\"ds_info: \\n\", ds_info)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# tfds.show_examples(train_ds, ds_info)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m (train_ds, test_ds)\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# 2.1 Load Dataset\n",
    "(train_ds, test_ds), ds_info = tfds.load ('mnist', split =['train', 'test'], as_supervised = True, with_info = True)\n",
    "\n",
    "# Info on the dataset (refresher)\n",
    "# print(\"ds_info: \\n\", ds_info)\n",
    "# tfds.show_examples(train_ds, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.2 Data Pipeline\n",
    "def prepare_data(dataset, batchsize):\n",
    "\n",
    "    '''\n",
    "    :param dataset: the dataset to be prepared for input into the network\n",
    "    :return: 2 datasets, one each for each of the math problems defined (see below), created after the original database was preprocessed with the\n",
    "    steps below\n",
    "    '''\n",
    "\n",
    "    # Step One - General Preprocessing\n",
    "\n",
    "    # convert data from uint8 to float32\n",
    "    dataset = dataset.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "\n",
    "    # flatten the images into vectors\n",
    "    dataset = dataset.map(lambda img, target: (tf.reshape(img, (-1,)), target))\n",
    "\n",
    "    # input normalization, just bringing image values from range [0, 255] to [-1, 1]\n",
    "    dataset = dataset.map(lambda img, target: ((img / 128.) - 1., target))\n",
    "\n",
    "    # Step 2 - Pairing Data Tuples & Respective Parameterized Targets\n",
    "\n",
    "    # create a dataset that contains 2000 samples from the overall dataset paired with 2000 other samples\n",
    "    data = tf.data.Dataset.zip((dataset.shuffle(2000), dataset.shuffle(2000)))\n",
    "\n",
    "    # create the dataset for the first math problem (a + b >= 5) - remembering to cast to int versus boolean!\n",
    "    greateqfive = data.map(lambda x1, x2: (x1[0], x2[0], x1[1]+x2[1]>=5))\n",
    "    greateqfive = greateqfive.map(lambda x1, x2, t: (x1, x2, tf.cast(t, tf.int32)))\n",
    "\n",
    "    # create the dataset for the second math problem (a - b = y)\n",
    "    subtr = data.map(lambda x1, x2: (x1[0], x2[0], x1[1]-x2[1]))\n",
    "\n",
    "    # Step 3 - Batching & Prefetching\n",
    "\n",
    "    # run batching and prefetching for both datasets\n",
    "    greateqfive = greateqfive.batch(batchsize)\n",
    "    greateqfive = greateqfive.prefetch(tf.data.AUTOTUNE)\n",
    "    subtr = subtr.batch(batchsize)\n",
    "    subtr = subtr.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # return BOTH datasets\n",
    "    return greateqfive, subtr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 784) (32, 784) (32,)\n",
      "(32, 784) (32, 784) (32,)\n",
      "(32, 784) (32, 784) (32,)\n",
      "(32, 784) (32, 784) (32,)\n"
     ]
    }
   ],
   "source": [
    "# Check data pipeline by examining one example from each of the four created datasets (one for each math problem for train and test)\n",
    "\n",
    "train_ds_gef, train_ds_subtr = prepare_data(train_ds, batchsize = 32)\n",
    "test_ds_gef, test_ds_subtr = prepare_data(test_ds, batchsize = 32)\n",
    "\n",
    "for img1, img2, label in train_ds_gef.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "\n",
    "for img1, img2, label in train_ds_subtr.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "\n",
    "for img1, img2, label in test_ds_gef.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "\n",
    "for img1, img2, label in test_ds_subtr.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 3: Building Shared Weight Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, activation, outputunits, optimizer):\n",
    "\n",
    "        '''\n",
    "        creates a neural network model with 2 hidden layers and an output layer\n",
    "        '''\n",
    "\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # create 2 hidden layers with 256 units and ReLU as the activation function\n",
    "        self.hidden_layer_1 = Dense(units=256, activation=tf.nn.relu)\n",
    "        self.hidden_layer_2 = Dense(units=256, activation=tf.nn.relu)\n",
    "\n",
    "        # Concatenation Layer?\n",
    "\n",
    "        # create an output layer with the specified number of output units and the chosen activation function\n",
    "        self.output = Dense(units=outputunits, activation=activation)\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, input1, input2):\n",
    "\n",
    "        '''\n",
    "        :param input: input to the network (tensor)\n",
    "        :return: output of final layer\n",
    "        '''\n",
    "\n",
    "        i1 = self.hidden_layer_1(input1)\n",
    "        i1 = self.hidden_layer_2(i1)\n",
    "        i1 = self.output_layer(i1)\n",
    "\n",
    "        i2 = self.hidden_layer_1(input2)\n",
    "        i2 = self.hidden_layer_2(i2)\n",
    "        i2 = self.output_layer(i2)\n",
    "        \n",
    "        # Concatenation Layer?\n",
    "\n",
    "\n",
    "    # a suggestion:\n",
    "    @tf.function\n",
    "    def __call__(self, input: tuple):\n",
    "        \n",
    "        # feed both inputs seperatedly into a layer, then concatenate the results\n",
    "        i1 = self.hidden_layer_1(input[0])\n",
    "        i2 = self.hidden_layer_1(input[1])\n",
    "        i = tf.concat([i1, i2], axis=0)    # e.g. (32,784) + (32,784) -> (32, 1568)\n",
    "        i = self.hidden_layer_2(i)\n",
    "\n",
    "        # parameterize the model to use the correct activation functions for subtasks (1) and subtask (2) respectively\n",
    "        if (input == train_ds_gef or input == test_ds_gef): \n",
    "            self.output = Dense(units=2, activation=tf.nn.sigmoid)\n",
    "            i = self.output(input)\n",
    "        elif (input == train_ds_subtr or input == test_ds_subtr):\n",
    "            self.output = Dense(units=10, activation=tf.nn.softmax)\n",
    "            i = self.output(input)\n",
    "\n",
    "        return i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 4: Training the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def training(subtask, optimizer):\n",
    "    '''\n",
    "    :param subtask: defines the subtask to be solved, 0 is a + b >= 5, 1 is a - b = y\n",
    "    :param optimizer: the optimizer function to use (based on the task)\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    # Create the model based on the settings above\n",
    "\n",
    "    #Note - ignore the fact that train_ds and test_ds may be flagged as not defined; when the whole program is run, this should not be an issue\n",
    "    train_ds_gef, train_ds_subtr = prepare_data(train_ds, batchsize = 32)\n",
    "    test_ds_gef, test_ds_subtr = prepare_data(test_ds, batchsize = 32)\n",
    "\n",
    "    if subtask == 0:\n",
    "        activation = tf.nn.softmax\n",
    "        outputunits = 10\n",
    "        train_ds = train_ds_gef\n",
    "        test_ds = test_ds_gef\n",
    "\n",
    "    else:\n",
    "        activation = tf.nn.sigmoid\n",
    "        outputunits = 2\n",
    "        train_ds = train_ds_subtr\n",
    "        test_ds = test_ds_subtr\n",
    "\n",
    "    # Initiate a model with the requested parameters\n",
    "\n",
    "    network = MyModel(activation,outputunits,optimizer)\n",
    "\n",
    "    # Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train a model to solve the first math problem\n",
    "# Binary Crossentropy is good for binary classification problems\n",
    "training(0, tf.keras.losses.BinaryCrossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train a model to solve the second math problem\n",
    "# Mean Squared Error is good for continuous output problems\n",
    "training(1, tf.keras.losses.MeanSquaredError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 5 - Experiments\n",
    "\n",
    "Run training w/ classic SGD (no momentum)\n",
    "\n",
    "Run training w/ Adam\n",
    "\n",
    "Run training w/ SGD + Momentum\n",
    "\n",
    "Run training w/ RMSrop\n",
    "\n",
    "Run training w/ AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the results of the above training runs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9045caf6303e7720903cf179822b02fa228c285a06d63d48b635a33538dcbdb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
