{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IANNwTF HW 4\n",
    "## Group 10\n",
    "\n",
    "The following contains our solution to the exercises in IANNwTF HW 04. A Jupyter notebook versus a module format was chosen this time for purposes of organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assigment 1: Reviews\n",
    "We review the homeworks for Groups 15 and 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 2: MNIST Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 Preparing the MNIST Math Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prizl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Needed Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.1 Load Dataset\n",
    "(train_ds, test_ds), ds_info = tfds.load ('mnist', split =['train', 'test'], as_supervised = True, with_info = True)\n",
    "\n",
    "# Info on the dataset (refresher)\n",
    "# print(\"ds_info: \\n\", ds_info)\n",
    "# tfds.show_examples(train_ds, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.2 Data Pipeline\n",
    "def prepare_data(dataset, batchsize):\n",
    "\n",
    "    '''\n",
    "    :param dataset: the dataset to be prepared for input into the network\n",
    "    :return: 2 datasets, one each for each of the math problems defined (see below), created after the original database was preprocessed with the\n",
    "    steps below\n",
    "    '''\n",
    "\n",
    "    # Step One - General Preprocessing\n",
    "\n",
    "    # convert data from uint8 to float32\n",
    "    dataset = dataset.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "\n",
    "    # flatten the images into vectors\n",
    "    dataset = dataset.map(lambda img, target: (tf.reshape(img, (-1,)), target))\n",
    "\n",
    "    # input normalization, just bringing image values from range [0, 255] to [-1, 1]\n",
    "    dataset = dataset.map(lambda img, target: ((img / 128.) - 1., target))\n",
    "\n",
    "    # Step 2 - Pairing Data Tuples & Respective Parameterized Targets\n",
    "\n",
    "    # create a dataset that contains 2000 samples from the overall dataset paired with 2000 other samples\n",
    "    data = tf.data.Dataset.zip((dataset.shuffle(2000), dataset.shuffle(2000)))\n",
    "\n",
    "    # create the dataset for the first math problem (a + b >= 5) - remembering to cast to int versus boolean!\n",
    "    greateqfive = data.map(lambda x1, x2: (x1[0], x2[0], x1[1]+x2[1]>=5))\n",
    "    greateqfive = greateqfive.map(lambda x1, x2, t: (x1, x2, tf.cast(t, tf.int32)))\n",
    "\n",
    "    # create the dataset for the second math problem (a - b = y)\n",
    "    subtr = data.map(lambda x1, x2: (x1[0], x2[0], x1[1]-x2[1]))\n",
    "\n",
    "    # Step 3 - Batching & Prefetching\n",
    "\n",
    "    # run batching and prefetching for both datasets\n",
    "    greateqfive = greateqfive.batch(batchsize)\n",
    "    greateqfive = greateqfive.prefetch(tf.data.AUTOTUNE)\n",
    "    subtr = subtr.batch(batchsize)\n",
    "    subtr = subtr.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # return BOTH datasets\n",
    "    return greateqfive, subtr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 784) (32, 784) (32,)\n",
      "(32, 784) (32, 784) (32,)\n",
      "(32, 784) (32, 784) (32,)\n",
      "(32, 784) (32, 784) (32,)\n"
     ]
    }
   ],
   "source": [
    "# Check data pipeline by examining one example from each of the four created datasets (one for each math problem for train and test)\n",
    "\n",
    "train_ds_gef, train_ds_subtr = prepare_data(train_ds, batchsize = 32)\n",
    "test_ds_gef, test_ds_subtr = prepare_data(test_ds, batchsize = 32)\n",
    "\n",
    "for img1, img2, label in train_ds_gef.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "\n",
    "for img1, img2, label in train_ds_subtr.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "\n",
    "for img1, img2, label in test_ds_gef.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "\n",
    "for img1, img2, label in test_ds_subtr.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 3: Building Shared Weight Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a suggestion:\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, numlayers, subtask):\n",
    "\n",
    "        '''\n",
    "        param: numlayers - the desired number of hidden layers\n",
    "        param: subtask - the subtask the network is being asked to solve (relevant for output layer)\n",
    "        '''\n",
    "    \t\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # create 2 hidden layers with 256 units and ReLU as the activation function\n",
    "\n",
    "        # self.hidden_layer_1 = Dense(units=256, activation=tf.nn.relu)\n",
    "        # self.hidden_layer_2 = Dense(units=256, activation=tf.nn.relu)\n",
    "\n",
    "        # add desired number of hidden layers\n",
    "        for i in range(numlayers):\n",
    "            self.layers.append(Dense(units=256, activation=tf.nn.relu))\n",
    "\n",
    "        self.subtask = subtask\n",
    "\n",
    "        if subtask == 0:\n",
    "            self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "        else:\n",
    "            self.loss_function = tf.keras.losses.MSE()\n",
    "\n",
    "        self.metrics_list = [\n",
    "                    tf.keras.metrics.Mean(name=\"loss\"),\n",
    "                    tf.keras.metrics.BinaryAccuracy(name=\"acc\"), # only for subtask 0, not for subtask 1\n",
    "                    # tf.keras.metrics.TopKCategoricalAccuracy(3,name=\"top-3-acc\") \n",
    "                    ]\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, input: tuple):\n",
    "        \n",
    "        # feed both inputs seperatedly into a layer, then concatenate the results before passing activity to the next layer\n",
    "\n",
    "        # i1 = self.hidden_layer_1(input[0])\n",
    "        # i2 = self.hidden_layer_1(input[1])\n",
    "        # i = tf.concat([i1, i2], axis=0)    # e.g. (32,784) + (32,784) -> (32, 1568)\n",
    "        # i = self.hidden_layer_2(i)\n",
    "\n",
    "        # feed the activity through the network UP TO the output layer\n",
    "        for i in self.layers:\n",
    "            if i == 0:\n",
    "                i1 = self.layers[i](input[0])\n",
    "                i2 = self.layers[i](input[1])\n",
    "                signal = tf.concat([i1, i2], axis=0)\n",
    "            else:\n",
    "                signal = self.layers[i](signal)\n",
    "\n",
    "        # create an output layer based on the\n",
    "        if self.subtask == 0:\n",
    "            self.output = Dense(units=2, activation=tf.nn.sigmoid)\n",
    "            signal = self.output(signal)\n",
    "        elif self.subtask==1:\n",
    "            self.output = Dense(units=10, activation=tf.nn.softmax)\n",
    "            signal = self.output(signal)\n",
    "\n",
    "        return signal\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    def train_step(self, input):\n",
    "        img1, img2, label = input\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self((img1, img2), training=True)\n",
    "            loss = self.loss_function(label, output)\n",
    "\n",
    "        gradients = tape.gradient(loss,self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # update loss metric\n",
    "        self.metrics[0].update_state(loss)\n",
    "        \n",
    "        # for all metrics except loss, update states (accuracy etc.)\n",
    "        for metric in self.metrics[1:]:\n",
    "            metric.update_state(label, output) # + tf.reduce_sum(self.losses)\n",
    "\n",
    "        # Return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, input):\n",
    "\n",
    "        img1, img2, label = input\n",
    "\n",
    "        output = self((img1, img2), training=False)\n",
    "        loss = self.loss_function(label, output) # + tf.reduce_sum(self.losses)\n",
    "\n",
    "        # update loss metric\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        # for accuracy metrics:\n",
    "        for metric in self.metrics[1:]:\n",
    "            metric.update_state(label, output)\n",
    "\n",
    "        # Return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 4: Training the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate the logs and metrics\n",
    "config_name= \"config_name\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
    "val_log_path = f\"logs/{config_name}/{current_time}/val\"\n",
    "\n",
    "# log writer for training metrics\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "\n",
    "# log writer for validation metrics\n",
    "val_summary_writer = tf.summary.create_file_writer(val_log_path)\n",
    "\n",
    "# Initiate epochs and learning rate as global variables\n",
    "epochs = 10\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def training(subtask):#, optimizer):\n",
    "    '''\n",
    "    :param subtask: defines the subtask to be solved, 0 is a + b >= 5, 1 is a - b = y\n",
    "    :param optimizer: the optimizer function to use\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    # make the if statement\n",
    "\n",
    "    # Initiate a model with the requested parameters\n",
    "    network = MyModel(2, subtask)\n",
    "\n",
    "    # Initialize the datasets for the two problems\n",
    "\n",
    "    # Note - ignore the fact that train_ds and test_ds may be flagged as not defined; when the whole program is run, this should not be an issue\n",
    "    train_ds_gef, train_ds_subtr = prepare_data(train_ds, batchsize = 32)\n",
    "    test_ds_gef, test_ds_subtr = prepare_data(test_ds, batchsize = 32)\n",
    "\n",
    "    # Initialize the train and test datasets, and the loss function, based on the subtask\n",
    "    if subtask == 0:\n",
    "        train = train_ds_gef\n",
    "        test = test_ds_gef\n",
    "        # network.loss_function = tf.keras.losses.BinaryCrossentropy\n",
    "\n",
    "    else:\n",
    "        train = train_ds_subtr\n",
    "        test = test_ds_subtr\n",
    "        # network.loss_function = tf.keras.losses.MeanSquaredError\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "\n",
    "        for data in tqdm.tqdm(train,position=1, leave=True):\n",
    "            metrics = network.train_step(data)\n",
    "\n",
    "            with train_summary_writer.as_default():\n",
    "                for metric in network.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(),step=epoch)\n",
    "\n",
    "\n",
    "        # print the end acc and loss\n",
    "        print([f\"{key}: {value.numpy()}\" for (key,value) in metrics.items()])\n",
    "\n",
    "        # reset metrics for next round\n",
    "        network.reset_metrics()\n",
    "\n",
    "        # Testing\n",
    "        for data in test:\n",
    "            metrics = network.test_step(data)\n",
    "\n",
    "            # log the accs and losses\n",
    "            with val_summary_writer.as_default():\n",
    "                for metric in network.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step = epoch)\n",
    "\n",
    "        # print the end acc and loss\n",
    "        print([f\"val_{key}: {value.numpy()}\" for (key,value) in metrics.items()])\n",
    "\n",
    "        # reset all metrics\n",
    "        network.reset_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf____call__() got an unexpected keyword argument 'training'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\prizl\\Documents\\GitHub\\IANNwTFGr10\\Homework\\04\\Gr10HW04.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train a model to solve the first math problem\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m training(\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\prizl\\Documents\\GitHub\\IANNwTFGr10\\Homework\\04\\Gr10HW04.ipynb Cell 14\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(subtask)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStarting Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(train,position\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     metrics \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mwith\u001b[39;00m train_summary_writer\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m network\u001b[39m.\u001b[39mmetrics:\n",
      "\u001b[1;32mc:\\Users\\prizl\\Documents\\GitHub\\IANNwTFGr10\\Homework\\04\\Gr10HW04.ipynb Cell 14\u001b[0m in \u001b[0;36mMyModel.train_step\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m img1, img2, label \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m((img1, img2), training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_function(label, output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X16sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m gradients \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf____call__() got an unexpected keyword argument 'training'\n"
     ]
    }
   ],
   "source": [
    "# Train a model to solve the first math problem\n",
    "training(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train a model to solve the second math problem\n",
    "training(1, tf.optimizers.Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 5 - Experiments\n",
    "\n",
    "Run training w/ classic SGD (no momentum)\n",
    "\n",
    "Run training w/ Adam\n",
    "\n",
    "Run training w/ SGD + Momentum\n",
    "\n",
    "Run training w/ RMSrop\n",
    "\n",
    "Run training w/ AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the results of the above training runs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9045caf6303e7720903cf179822b02fa228c285a06d63d48b635a33538dcbdb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
