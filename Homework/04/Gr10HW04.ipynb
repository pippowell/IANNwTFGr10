{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IANNwTF HW 4\n",
    "## Group 10\n",
    "\n",
    "The following contains our solution to the exercises in IANNwTF HW 04. A Jupyter notebook versus a module format was chosen this time for purposes of organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assigment 1: Reviews\n",
    "We review the homeworks for Groups 15 and 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 2: MNIST Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 Preparing the MNIST Math Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Needed Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tqdm\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.1 Load Dataset\n",
    "(train_ds, test_ds), ds_info = tfds.load ('mnist', split =['train', 'test'], as_supervised = True, with_info = True)\n",
    "\n",
    "# Info on the dataset (refresher)\n",
    "# print(\"ds_info: \\n\", ds_info)\n",
    "# tfds.show_examples(train_ds, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.2 Data Pipeline\n",
    "def prepare_data(dataset, batchsize):\n",
    "\n",
    "    '''\n",
    "    :param dataset: the dataset to be prepared for input into the network\n",
    "    :param batchsize: the desired batchsize\n",
    "    :return: 2 datasets, one each for each of the math problems defined (see below), created after the original database was preprocessed with the\n",
    "    steps below\n",
    "    '''\n",
    "\n",
    "    # Step 1 - General Preprocessing\n",
    "\n",
    "    # convert data from uint8 to float32\n",
    "    dataset = dataset.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "\n",
    "    # flatten the images into vectors\n",
    "    dataset = dataset.map(lambda img, target: (tf.reshape(img, (-1,)), target))\n",
    "\n",
    "    # input normalization, just bringing image values from range [0, 255] to [-1, 1]\n",
    "    dataset = dataset.map(lambda img, target: ((img / 128.) - 1., target))\n",
    "    \n",
    "    # create one-hot targets\n",
    "    dataset = dataset.map(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
    "\n",
    "    # Step 2 - Pairing Data Tuples & Respective Parameterized Targets\n",
    "\n",
    "    # create a dataset that contains 2000 samples from the overall dataset paired with 2000 other samples\n",
    "    data = tf.data.Dataset.zip((dataset.shuffle(2000), dataset.shuffle(2000)))\n",
    "\n",
    "    # create the dataset for the first math problem (a + b >= 5) - remembering to cast to int versus boolean!\n",
    "    greateqfive = data.map(lambda x1, x2: (x1[0], x2[0], x1[1]+x2[1]>=5))\n",
    "    greateqfive = greateqfive.map(lambda x1, x2, t: (x1, x2, tf.cast(t, tf.int32)))\n",
    "\n",
    "    # create the dataset for the second math problem (a - b = y)\n",
    "    subtr = data.map(lambda x1, x2: (x1[0], x2[0], x1[1]-x2[1]))\n",
    "\n",
    "    # Step 3 - Batching & Prefetching\n",
    "    greateqfive = greateqfive.batch(batchsize)\n",
    "    greateqfive = greateqfive.prefetch(tf.data.AUTOTUNE)\n",
    "    subtr = subtr.batch(batchsize)\n",
    "    subtr = subtr.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # return BOTH datasets\n",
    "    return greateqfive, subtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 784) (32, 784) (32, 10)\n",
      "(32, 784) (32, 784) (32, 10)\n",
      "(32, 784) (32, 784) (32, 10)\n",
      "(32, 784) (32, 784) (32, 10)\n"
     ]
    }
   ],
   "source": [
    "# Check data pipeline by examining one example from each of the four created datasets (one for each math problem for train and test)\n",
    "\n",
    "train_ds_gef, train_ds_subtr = prepare_data(train_ds, batchsize = 32)\n",
    "test_ds_gef, test_ds_subtr = prepare_data(test_ds, batchsize = 32)\n",
    "\n",
    "for img1, img2, label in train_ds_gef.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "\n",
    "for img1, img2, label in train_ds_subtr.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "\n",
    "for img1, img2, label in test_ds_gef.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n",
    "\n",
    "for img1, img2, label in test_ds_subtr.take(1):\n",
    "    print(img1.shape, img2.shape, label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate the logs and metrics\n",
    "config_name= \"config_name\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
    "val_log_path = f\"logs/{config_name}/{current_time}/val\"\n",
    "\n",
    "# log writer for training metrics\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "\n",
    "# log writer for validation metrics\n",
    "val_summary_writer = tf.summary.create_file_writer(val_log_path)\n",
    "\n",
    "# Initiate epochs and learning rate as global variables\n",
    "epochs = 5 # 10\n",
    "learning_rate = 0.1 # 0.01\n",
    "\n",
    "# Define arrays for saving values for later visualization\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Assignment 3: Building Shared Weight Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, numlayers, subtask, optimizer):\n",
    "\n",
    "        '''\n",
    "        param: numlayers - the desired number of hidden layers\n",
    "        param: subtask - the subtask the network is being asked to solve (relevant for output layer)\n",
    "        param: optimizer - the optimizer to be used\n",
    "        '''\n",
    "\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.subtask = subtask\n",
    "\n",
    "        self.layerlist = [Dense(layers, activation=\"relu\") for layers in range(numlayers)]\n",
    "\n",
    "        if subtask == 0:\n",
    "            self.output_layer = Dense(units=1, activation=tf.nn.sigmoid)\n",
    "            self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "        elif subtask == 1:\n",
    "            self.output_layer = Dense(units=10, activation=tf.nn.softmax) # not 10 units, since the label.shape is (32,) not (32,10)\n",
    "            self.loss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "        self.metrics_list = [\n",
    "                    tf.keras.metrics.Mean(name=\"loss\"),\n",
    "                    tf.keras.metrics.BinaryAccuracy(name=\"acc\"), # only for subtask 0, not for subtask 1\n",
    "                    #tf.keras.metrics.TopKCategoricalAccuracy(3,name=\"top-3-acc\")\n",
    "                    ]\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, input: tuple, training = False):\n",
    "\n",
    "        # feed both inputs separately into the first layer, then concatenate the results before passing activity through the rest of the network UP TO the output layer\n",
    "        for layer in range(len(self.layerlist)):\n",
    "             if layer == 0:\n",
    "                 i1 = self.layerlist[layer](input[0])\n",
    "                 i2 = self.layerlist[layer](input[1])\n",
    "                 i = tf.concat([i1, i2], axis=1)   # e.g. axis=1: (32,784) + (32,784) -> (32, 1568)\n",
    "             else:\n",
    "                 i = self.layerlist[layer](i)\n",
    "\n",
    "        # run the activity through the output layer after it passes through the hidden layers\n",
    "        output = self.output_layer(i)\n",
    "\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, input):\n",
    "        img1, img2, label = input\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = self((img1, img2), training=True)\n",
    "            loss = self.loss_function(label, prediction)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        # update loss metric\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        # for all metrics except loss, update states (accuracy etc.)\n",
    "        for metric in self.metrics[1:]:\n",
    "            metric.update_state(label, prediction) # + tf.reduce_sum(self.losses)\n",
    "\n",
    "        # Return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(self, input):\n",
    "\n",
    "        img1, img2, label = input\n",
    "\n",
    "        prediction = self((img1, img2), training=False)\n",
    "        loss = self.loss_function(label, prediction) # + tf.reduce_sum(self.losses)\n",
    "\n",
    "        # update loss metric\n",
    "        self.metrics[0].update_state(loss)\n",
    "\n",
    "        # for accuracy metrics:\n",
    "        for metric in self.metrics[1:]:\n",
    "            metric.update_state(label, prediction)\n",
    "\n",
    "        # Return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Assignment 4: Training the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def training(numlayers, subtask, optimizer):\n",
    "    '''\n",
    "    :param: numlayers: the number of layers desired in the network to be trained\n",
    "    :param subtask: defines the subtask to be solved, 0 is a + b >= 5, 1 is a - b = y\n",
    "    :param optimizer: the optimizer function to use\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    # Initiate a model with the requested parameters\n",
    "    network = MyModel(numlayers, subtask, optimizer)\n",
    "\n",
    "    # Initialize the train and test datasets, and the loss function, based on the subtask\n",
    "    if subtask == 0:\n",
    "        train = train_ds_gef\n",
    "        test = test_ds_gef\n",
    "\n",
    "    else:\n",
    "        train = train_ds_subtr\n",
    "        test = test_ds_subtr\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "\n",
    "        for data in tqdm.tqdm(train, position=0, leave=True):\n",
    "            metrics = network.train_step(data)\n",
    "\n",
    "            with train_summary_writer.as_default():\n",
    "                for metric in network.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "\n",
    "        # Piper Attempt at Retrieve Mets for Vis\n",
    "        #train_losses.append(network.metrics[0].result())\n",
    "        #train_accuracies.append(network.metrics[1].result())\n",
    "\n",
    "        # print the end acc and loss\n",
    "        print([f\"train_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "\n",
    "        # make a list of losses and accuracies\n",
    "        for (key, value) in metrics.items():\n",
    "            if key == \"loss\":\n",
    "                train_losses.append(value.numpy())\n",
    "            elif key == \"acc\":\n",
    "                train_accuracies.append(value.numpy())\n",
    "\n",
    "        # reset metrics for next round\n",
    "        network.reset_metrics()\n",
    "\n",
    "        # Testing\n",
    "        for data in test:\n",
    "            metrics = network.test_step(data)\n",
    "\n",
    "            # log the accs and losses\n",
    "            with val_summary_writer.as_default():\n",
    "                for metric in network.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step = epoch)\n",
    "\n",
    "        # Piper Attempt at Retrieve Mets for Vis\n",
    "        #test_losses.append(network.metrics[2].result())\n",
    "        #test_accuracies.append(network.metrics[3].result())\n",
    "\n",
    "        # print the end acc and loss\n",
    "        print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "\n",
    "        # make a list of losses and accuracies\n",
    "        for (key, value) in metrics.items():\n",
    "            if key == \"loss\":\n",
    "                val_losses.append(value.numpy())\n",
    "            elif key == \"acc\":\n",
    "                val_accuracies.append(value.numpy())\n",
    "\n",
    "        # reset all metrics\n",
    "        network.reset_metrics()\n",
    "\n",
    "        #return train_losses,train_accuracies,test_losses,test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:11<00:00, 163.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_loss: 0.1898764669895172', 'train_acc: 0.8201299905776978']\n",
      "['val_loss: 0.1899721622467041', 'val_acc: 0.8200399875640869']\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 196.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_loss: 0.1900428682565689', 'train_acc: 0.8199633359909058']\n",
      "['val_loss: 0.18947292864322662', 'val_acc: 0.8205199837684631']\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 218.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_loss: 0.1900399625301361', 'train_acc: 0.8199666738510132']\n",
      "['val_loss: 0.190471351146698', 'val_acc: 0.8195400238037109']\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 209.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_loss: 0.19020633399486542', 'train_acc: 0.8198000192642212']\n",
      "['val_loss: 0.19073088467121124', 'val_acc: 0.8192600011825562']\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1028/1875 [00:05<00:04, 205.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\prizl\\Documents\\GitHub\\IANNwTFGr10\\Homework\\04\\Gr10HW04.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m training(\u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m, tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49moptimizers\u001b[39m.\u001b[39;49mAdam())\n",
      "\u001b[1;32mc:\\Users\\prizl\\Documents\\GitHub\\IANNwTFGr10\\Homework\\04\\Gr10HW04.ipynb Cell 14\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(numlayers, subtask, optimizer)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X36sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(train, position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     metrics \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X36sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mwith\u001b[39;00m train_summary_writer\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prizl/Documents/GitHub/IANNwTFGr10/Homework/04/Gr10HW04.ipynb#X36sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m network\u001b[39m.\u001b[39mmetrics:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training(2, 1, tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train a model to solve the first math problem\n",
    "training(2, 0, tf.keras.optimizers.Adam())\n",
    "adamlist_0 = [train_losses, train_accuracies, val_losses, val_accuracies]\n",
    "\n",
    "training(2, 0, tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.0))\n",
    "SDG_0 = [train_losses, train_accuracies, val_losses, val_accuracies]\n",
    "\n",
    "training(2, 0, tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.5))\n",
    "SDG_mom_0 = [train_losses, train_accuracies, val_losses, val_accuracies]\n",
    "\n",
    "training(2, 0, tf.keras.optimizers.RMSprop())\n",
    "RMS_0 = [train_losses, train_accuracies, val_losses, val_accuracies]\n",
    "\n",
    "training(2, 0, tf.keras.optimizers.Adagrad())\n",
    "Adagrad_0 = [train_losses, train_accuracies, val_losses, val_accuracies]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_losses: [0.5248539, 0.44129115, 0.4380492, 0.43805572, 0.43716604, 17.613567, 17.681034, 17.7534, 17.810934, 17.7327, 0.5271127, 0.44131684, 0.4377605, 0.43741772, 0.4374252]\n",
      "train_accuracies: [0.83998334, 0.84075, 0.841, 0.84098333, 0.8415167, 0.0898, 0.0892, 0.090966664, 0.08918333, 0.08958333, 0.8401833, 0.8408667, 0.8411667, 0.84136665, 0.84136665]\n",
      "val_losses: [0.45374647, 0.43982127, 0.43991643, 0.43541378, 0.44091251, 17.570387, 17.900259, 17.895267, 17.785244, 17.629494, 0.45314515, 0.430802, 0.44041282, 0.44805124, 0.4422544]\n",
      "val_accuracies: [0.8382, 0.8401, 0.8398, 0.8427, 0.8392, 0.09, 0.0891, 0.0845, 0.0851, 0.0885, 0.8394, 0.8453, 0.8395, 0.835, 0.8388]\n"
     ]
    }
   ],
   "source": [
    "# Train a model to solve the first math problem\n",
    "training(2, 1, tf.keras.optimizers.Adam())\n",
    "adamlist_1 = [train_losses, train_accuracies, val_losses, val_accuracies]\n",
    "\n",
    "training(2, 0, tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.0))\n",
    "SDG_0 = [train_losses, train_accuracies, val_losses, val_accuracies]\n",
    "\n",
    "training(2, 0, tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.5))\n",
    "SDG_mom_0 = [train_losses, train_accuracies, val_losses, val_accuracies]\n",
    "\n",
    "training(2, 0, tf.keras.optimizers.RMSprop())\n",
    "RMS_0 = [train_losses, train_accuracies, val_losses, val_accuracies]\n",
    "\n",
    "training(2, 0, tf.keras.optimizers.Adagrad())\n",
    "Adagrad_0 = [train_losses, train_accuracies, val_losses, val_accuracies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "line1, = plt.plot(train_losses)\n",
    "line2, = plt.plot(val_losses)\n",
    "line3, = plt.plot(train_accuracies)\n",
    "line4, = plt.plot(val_accuracies)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend((line1, line2, line3, line4), (\"Training Loss\", \"Test Loss\", \"Training Accuracy\", \"Test Accuracy\"))\n",
    "# fig.savefig(\"Title-Of-The-Figure\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 217.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_loss: 17.613567352294922', 'train_acc: 0.08980000019073486']\n",
      "['val_loss: 17.57038688659668', 'val_acc: 0.09000000357627869']\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 214.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_loss: 17.681034088134766', 'train_acc: 0.08919999748468399']\n",
      "['val_loss: 17.900259017944336', 'val_acc: 0.08910000324249268']\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 204.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_loss: 17.753400802612305', 'train_acc: 0.09096666425466537']\n",
      "['val_loss: 17.895267486572266', 'val_acc: 0.08449999988079071']\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:10<00:00, 182.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_loss: 17.81093406677246', 'train_acc: 0.08918333053588867']\n",
      "['val_loss: 17.78524398803711', 'val_acc: 0.08510000258684158']\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 189.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_loss: 17.73270034790039', 'train_acc: 0.08958332985639572']\n",
      "['val_loss: 17.629493713378906', 'val_acc: 0.0885000005364418']\n"
     ]
    }
   ],
   "source": [
    "# Train a model to solve the second math problem\n",
    "training(2, 1, tf.keras.optimizers.Adam())\n",
    "#training(2, 1, tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.0))\n",
    "#training(2, 1, tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.5))\n",
    "#training(2, 1, tf.keras.optimizers.RMSprop())\n",
    "#training(2, 1, tf.keras.optimizers.Adagrad())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy does initially seem to go up over the epochs, but then drops again. But then this is the harder task I think. Visualization should be a matter of pulling out the metric results into the lists we created so we can use those lists for the next part. I tried this with the code I added above (marked as my attempt), but no luck.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 5 - Experiments\n",
    "\n",
    "Run training w/ classic SGD (no momentum)\n",
    "\n",
    "Run training w/ Adam\n",
    "\n",
    "Run training w/ SGD + Momentum\n",
    "\n",
    "Run training w/ RMSrop\n",
    "\n",
    "Run training w/ AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "line1, = plt.plot(train_losses)\n",
    "line2, = plt.plot(val_losses)\n",
    "line3, = plt.plot(train_accuracies)\n",
    "line4, = plt.plot(val_accuracies)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend((line1, line2, line3, line4), (\"Training Loss\", \"Test Loss\", \"Training Accuracy\", \"Test Accuracy\"))\n",
    "# fig.savefig(\"Title-Of-The-Figure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wooki) in QnA\n",
    "\n",
    "1. do we need to have a code that shows plots from different optimizers with one click \n",
    "or do we just need to save the plots from different optimizers after running multiple codes?\n",
    "\n",
    "2. the loss/acc for subtask 1 is off. maybe output unit should be 10 instead of 1 but that gives a dimension difference error.\n",
    "\n",
    "3. preprocessing in hw5\n",
    "\n",
    "4. input sizes throughout cnn in hw 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9045caf6303e7720903cf179822b02fa228c285a06d63d48b635a33538dcbdb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
